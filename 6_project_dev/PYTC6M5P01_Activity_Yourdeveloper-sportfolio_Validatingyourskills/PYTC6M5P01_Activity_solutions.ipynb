{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ec90d7",
   "metadata": {},
   "source": [
    "\n",
    "# Web Scraping Example with BeautifulSoup + Functions & Visualization\n",
    "\n",
    "## Objective:\n",
    "This notebook demonstrates how to:\n",
    "- Encapsulate scraping logic in functions\n",
    "- Parse HTML content with BeautifulSoup\n",
    "- Extract structured data (book titles, prices, ratings)\n",
    "- Store the data in a pandas DataFrame\n",
    "- Perform data cleaning and transformations in a separate function\n",
    "- Use basic data visualization to explore the results\n",
    "\n",
    "Although the data here is about books, these techniques apply to many domains, including the healthcare industry. The skills demonstrated—web scraping, data cleaning, and visualization—are highly relevant to data-driven roles across industries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure plots render inline for Jupyter Notebooks\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_books(num_pages=5):\n",
    "    \"\"\"\n",
    "    Scrapes books data from 'http://books.toscrape.com' for the specified number of pages.\n",
    "    \n",
    "    Parameters:\n",
    "        num_pages (int): Number of pages to scrape.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing titles, prices, availability, and rating data.\n",
    "    \"\"\"\n",
    "    base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "    all_titles = []\n",
    "    all_prices = []\n",
    "    all_availability = []\n",
    "    all_ratings = []\n",
    "    \n",
    "    for page in range(1, num_pages + 1):\n",
    "        url = base_url.format(page)\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            books = soup.find_all('article', class_='product_pod')\n",
    "            \n",
    "            for book in books:\n",
    "                # Title\n",
    "                title = book.h3.a['title']\n",
    "                \n",
    "                # Price\n",
    "                price = book.find('p', class_='price_color').text\n",
    "                cleaned_price = price.replace('£', '').encode('ascii', 'ignore').decode('ascii').strip()\n",
    "                price_value = float(cleaned_price)\n",
    "                \n",
    "                # Availability\n",
    "                availability = book.find('p', class_='instock availability').text.strip()\n",
    "                \n",
    "                # Rating\n",
    "                rating_tag = book.find('p', class_='star-rating')\n",
    "                rating_classes = rating_tag.get('class', [])\n",
    "                rating = rating_classes[1] if len(rating_classes) > 1 else None\n",
    "                \n",
    "                all_titles.append(title)\n",
    "                all_prices.append(price_value)\n",
    "                all_availability.append(availability)\n",
    "                all_ratings.append(rating)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve page {page}\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    data = {\n",
    "        'title': all_titles,\n",
    "        'price': all_prices,\n",
    "        'availability': all_availability,\n",
    "        'rating': all_ratings\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94758093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans and transforms the scraped DataFrame.\n",
    "    - Maps textual ratings to numeric values\n",
    "    - Checks for missing values\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The raw scraped DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned and transformed DataFrame.\n",
    "    \"\"\"\n",
    "    rating_map = {'One':1, 'Two':2, 'Three':3, 'Four':4, 'Five':5}\n",
    "    df['numeric_rating'] = df['rating'].map(rating_map)\n",
    "    \n",
    "    missing_values_count = df.isnull().sum()\n",
    "    print(\"Missing Values Count before cleanup:\")\n",
    "    print(missing_values_count)\n",
    "    \n",
    "    df = df.dropna(subset=['numeric_rating'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_data(df):\n",
    "    \"\"\"\n",
    "    Creates basic visualizations for the scraped and cleaned data.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df['price'], kde=True)\n",
    "    plt.title(\"Distribution of Book Prices\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x='numeric_rating', data=df, palette='viridis')\n",
    "    plt.title(\"Count of Ratings\")\n",
    "    plt.xlabel(\"Rating (1-5)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x='numeric_rating', y='price', data=df, palette='magma')\n",
    "    plt.title(\"Price vs. Numeric Rating\")\n",
    "    plt.xlabel(\"Numeric Rating\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36711ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Scrape the data\n",
    "df = scrape_books(num_pages=5)\n",
    "\n",
    "# Step 2: Clean and transform the data\n",
    "df = clean_data(df)\n",
    "\n",
    "# Step 3: Explore the cleaned data\n",
    "print(\"DataFrame Head:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nSummary Statistics on Price:\")\n",
    "display(df['price'].describe())\n",
    "\n",
    "print(\"\\nValue Counts for Ratings:\")\n",
    "display(df['rating'].value_counts())\n",
    "\n",
    "# Step 4: Visualize the data\n",
    "visualize_data(df)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
