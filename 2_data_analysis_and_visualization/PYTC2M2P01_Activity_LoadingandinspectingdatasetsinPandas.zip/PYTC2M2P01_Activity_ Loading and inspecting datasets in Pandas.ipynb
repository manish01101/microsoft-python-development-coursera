{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55601b3d-cd9f-4c13-9eda-8cd27f54202c",
   "metadata": {},
   "source": [
    "## How to Interact with this Jupyter Notebook\n",
    "\n",
    "In this activity, you will use a Jupyter Notebook, which integrates both text and code. The gray boxes contain executable code, which you will run in order to view its output. The text in between the code provides instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af126b-b291-4ae1-8cf8-f3883f7195aa",
   "metadata": {},
   "source": [
    "## Scenario: Charting the Customer Journey with Pandas\n",
    "\n",
    "Imagine you're a Python developer at a rapidly growing e-commerce company. The marketing team is eager to understand customer behavior and preferences to tailor their campaigns and improve the overall shopping experience. They've provided you with a valuable dataset containing information about customers, their purchases, and demographics. \n",
    "\n",
    "Your task is to leverage your Python skills and the power of the Pandas library to load this dataset, explore its structure, and uncover preliminary insights that will guide further analysis. This initial exploration is crucial for understanding the data you're working with and making informed decisions about how to proceed with more in-depth analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc3f26",
   "metadata": {},
   "source": [
    "In the cell below, begin by importing the `pandas` library with the alias `pd`. Then, use `.read_csv()` to load the `customer_data_50.csv` file into a DataFrame named `customer_data`. \n",
    "\n",
    "Lastly, run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7c8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library with the alias 'pd'\n",
    "\n",
    "# insert code here \n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file 'customer_data_50.csv' into a DataFrame\n",
    "\n",
    "# insert code here \n",
    "customer_data = pd.read_csv('customer_data_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f7a73-2b4e-4d4d-8018-c6ee38acab95",
   "metadata": {},
   "source": [
    "Run the following cell, which will check the dimensions of your DataFrame using the `.shape` attribute. This tells you how many rows and columns your data has â€“ kind of like figuring out the size of a spreadsheet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0249d4-c0dd-4cba-8f4b-070130e8f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the DataFrame (rows, columns): (50, 13)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the DataFrame (rows, columns)\n",
    "print(\"\\nShape of the DataFrame (rows, columns):\", customer_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7982d00-92d7-4db5-b529-37aa53d03b0b",
   "metadata": {},
   "source": [
    "Next, you'll inspect the data using the `df.head()` function, which allows you to view the first few rows of the DataFrame. This gives you a quick look at the data's structure and content.\n",
    "\n",
    "In the cell below, use `df.head()`to display the first 5 rows of the `customer_data` DataFrame.  Then, run the cell and take a moment to observe the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e941605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "\n",
      "   customer_id first_name  last_name                       email gender  age  \\\n",
      "0         1001     Sophia      Smith    sophia.smith@example.com      M   54   \n",
      "1         1002     Joseph      Smith    joseph.smith@example.com      M   66   \n",
      "2         1003       John   Anderson   john.anderson@example.com      F   56   \n",
      "3         1004       Emma  Hernandez  emma.hernandez@example.com      M   44   \n",
      "4         1005      Emily     Garcia    emily.garcia@example.com      F   25   \n",
      "\n",
      "          city state country  purchase_count  total_spend  avg_order_value  \\\n",
      "0  San Antonio    TX     USA               5          965            193.0   \n",
      "1  Los Angeles    CA     USA               7         1246            178.0   \n",
      "2      Phoenix    AZ     USA               1          199            199.0   \n",
      "3  Los Angeles    CA     USA              14         3752            268.0   \n",
      "4       Dallas    TX     USA              12         1620            135.0   \n",
      "\n",
      "           last_purchase_date  \n",
      "0  2023-09-12 15:28:32.140488  \n",
      "1  2023-08-25 15:28:32.140488  \n",
      "2  2024-04-28 15:28:32.140488  \n",
      "3  2024-01-01 15:28:32.140488  \n",
      "4  2023-12-09 15:28:32.140488  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(\"First 5 rows:\\n\")\n",
    "\n",
    "# insert code here \n",
    "print(customer_data.head()) #delete this adeeb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d50c2-5e1e-46ee-b2f0-d43f2d631d8d",
   "metadata": {},
   "source": [
    "Now, you'll use the `df.info()` function, which provides a concise summary of the DataFrame, including the column names, their data types, and the number of non-null values.\n",
    "\n",
    "In the cell below, use `df.info()` to print information about the `customer_data` DataFrame  Then, run the cell and take a moment to observe the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933fbc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names and their data types:\n",
      "\n",
      "<bound method NDFrame.head of     customer_id first_name  last_name                            email gender  \\\n",
      "0          1001     Sophia      Smith         sophia.smith@example.com      M   \n",
      "1          1002     Joseph      Smith         joseph.smith@example.com      M   \n",
      "2          1003       John   Anderson        john.anderson@example.com      F   \n",
      "3          1004       Emma  Hernandez       emma.hernandez@example.com      M   \n",
      "4          1005      Emily     Garcia         emily.garcia@example.com      F   \n",
      "5          1006        Ava     Taylor           ava.taylor@example.com      F   \n",
      "6          1007       Jane   Martinez        jane.martinez@example.com      F   \n",
      "7          1008     Daniel    Jackson       daniel.jackson@example.com      F   \n",
      "8          1009      David      Davis          david.davis@example.com      F   \n",
      "9          1010      Emily  Rodriguez      emily.rodriguez@example.com      M   \n",
      "10         1011        Mia     Taylor           mia.taylor@example.com      F   \n",
      "11         1012    Michael   Martinez     michael.martinez@example.com      M   \n",
      "12         1013     Sophia     Thomas        sophia.thomas@example.com      F   \n",
      "13         1014       Emma   Martinez        emma.martinez@example.com      F   \n",
      "14         1015      James  Rodriguez      james.rodriguez@example.com      F   \n",
      "15         1016      Emily      Lopez          emily.lopez@example.com      M   \n",
      "16         1017     Joseph    Johnson       joseph.johnson@example.com      M   \n",
      "17         1018      David  Hernandez      david.hernandez@example.com      M   \n",
      "18         1019       Jane      Moore           jane.moore@example.com      M   \n",
      "19         1020    Abigail      Jones        abigail.jones@example.com      F   \n",
      "20         1021    Michael     Martin       michael.martin@example.com      F   \n",
      "21         1022     Sophia     Martin        sophia.martin@example.com      F   \n",
      "22         1023   Isabella      Brown       isabella.brown@example.com      M   \n",
      "23         1024  Charlotte  Rodriguez  charlotte.rodriguez@example.com      M   \n",
      "24         1025    Matthew     Taylor       matthew.taylor@example.com      M   \n",
      "25         1026       Jane  Hernandez       jane.hernandez@example.com      M   \n",
      "26         1027     Daniel   Martinez      daniel.martinez@example.com      M   \n",
      "27         1028        Mia      Smith            mia.smith@example.com      M   \n",
      "28         1029        Ava    Jackson          ava.jackson@example.com      M   \n",
      "29         1030     Daniel     Miller        daniel.miller@example.com      F   \n",
      "30         1031        Mia      Moore            mia.moore@example.com      F   \n",
      "31         1032     Olivia   Williams      olivia.williams@example.com      M   \n",
      "32         1033  Charlotte     Taylor     charlotte.taylor@example.com      M   \n",
      "33         1034        Ava      Moore            ava.moore@example.com      F   \n",
      "34         1035      David     Garcia         david.garcia@example.com      M   \n",
      "35         1036        Ava     Martin           ava.martin@example.com      F   \n",
      "36         1037     Daniel    Johnson       daniel.johnson@example.com      M   \n",
      "37         1038      Ethan    Johnson        ethan.johnson@example.com      F   \n",
      "38         1039        Mia      Davis            mia.davis@example.com      M   \n",
      "39         1040    Matthew     Garcia       matthew.garcia@example.com      F   \n",
      "40         1041        Mia      Davis            mia.davis@example.com      F   \n",
      "41         1042        Ava      Moore            ava.moore@example.com      M   \n",
      "42         1043    Michael    Jackson      michael.jackson@example.com      F   \n",
      "43         1044   Isabella      Lopez       isabella.lopez@example.com      M   \n",
      "44         1045      Emily   Williams       emily.williams@example.com      F   \n",
      "45         1046     Olivia     Miller        olivia.miller@example.com      M   \n",
      "46         1047    Abigail      Jones        abigail.jones@example.com      M   \n",
      "47         1048    Abigail   Williams     abigail.williams@example.com      M   \n",
      "48         1049       Emma      Jones           emma.jones@example.com      F   \n",
      "49         1050      David      Smith          david.smith@example.com      M   \n",
      "\n",
      "    age          city state country  purchase_count  total_spend  \\\n",
      "0    54   San Antonio    TX     USA               5          965   \n",
      "1    66   Los Angeles    CA     USA               7         1246   \n",
      "2    56       Phoenix    AZ     USA               1          199   \n",
      "3    44   Los Angeles    CA     USA              14         3752   \n",
      "4    25        Dallas    TX     USA              12         1620   \n",
      "5    69      San Jose    CA     USA              14         1792   \n",
      "6    63      New York    NY     USA               3          804   \n",
      "7    24       Phoenix    AZ     USA               8          864   \n",
      "8    59       Phoenix    AZ     USA              14         3304   \n",
      "9    31     San Diego    CA     USA               4          396   \n",
      "10   24       Houston    TX     USA              15         1020   \n",
      "11   54     San Diego    CA     USA               4         1196   \n",
      "12   29      New York    NY     USA              15         4440   \n",
      "13   45       Phoenix    AZ     USA              15         2190   \n",
      "14   53      San Jose    CA     USA              14         1498   \n",
      "15   64      San Jose    CA     USA              12         1152   \n",
      "16   63      San Jose    CA     USA               5          490   \n",
      "17   33        Dallas    TX     USA               3          405   \n",
      "18   43     San Diego    CA     USA              10         1710   \n",
      "19   19       Houston    TX     USA               1          262   \n",
      "20   38      New York    NY     USA               4          584   \n",
      "21   69       Houston    TX     USA               6          942   \n",
      "22   48  Philadelphia    PA     USA               2          380   \n",
      "23   43       Chicago    IL     USA               6         1716   \n",
      "24   51      New York    NY     USA               9         1746   \n",
      "25   55      San Jose    CA     USA               6         1350   \n",
      "26   43   Los Angeles    CA     USA              10         1830   \n",
      "27   38       Houston    TX     USA               8          872   \n",
      "28   51   Los Angeles    CA     USA               5          910   \n",
      "29   30     San Diego    CA     USA              15         1350   \n",
      "30   53       Phoenix    AZ     USA              12         2304   \n",
      "31   57      San Jose    CA     USA              11         1925   \n",
      "32   20     San Diego    CA     USA               2          562   \n",
      "33   28   Los Angeles    CA     USA               8         1904   \n",
      "34   64       Phoenix    AZ     USA               8         1416   \n",
      "35   47   Los Angeles    CA     USA               4          304   \n",
      "36   45     San Diego    CA     USA               6         1380   \n",
      "37   41       Phoenix    AZ     USA              10         1390   \n",
      "38   51      San Jose    CA     USA              12         2604   \n",
      "39   23  Philadelphia    PA     USA               7         1939   \n",
      "40   29       Houston    TX     USA              10          530   \n",
      "41   20     San Diego    CA     USA              15         3345   \n",
      "42   31     San Diego    CA     USA              13         3159   \n",
      "43   52      San Jose    CA     USA              10         2470   \n",
      "44   63   San Antonio    TX     USA              15         1920   \n",
      "45   30      San Jose    CA     USA               7          581   \n",
      "46   38        Dallas    TX     USA              11         2904   \n",
      "47   49       Phoenix    AZ     USA               4         1192   \n",
      "48   23       Chicago    IL     USA              10          780   \n",
      "49   24   Los Angeles    CA     USA               8         1000   \n",
      "\n",
      "    avg_order_value          last_purchase_date  \n",
      "0             193.0  2023-09-12 15:28:32.140488  \n",
      "1             178.0  2023-08-25 15:28:32.140488  \n",
      "2             199.0  2024-04-28 15:28:32.140488  \n",
      "3             268.0  2024-01-01 15:28:32.140488  \n",
      "4             135.0  2023-12-09 15:28:32.140488  \n",
      "5             128.0  2024-03-13 15:28:32.140488  \n",
      "6             268.0  2024-03-27 15:28:32.140488  \n",
      "7             108.0  2023-10-26 15:28:32.140488  \n",
      "8             236.0  2024-08-17 15:28:32.140488  \n",
      "9              99.0  2023-10-11 15:28:32.140488  \n",
      "10             68.0  2024-06-17 15:28:32.140488  \n",
      "11            299.0  2024-03-28 15:28:32.140488  \n",
      "12            296.0  2024-05-28 15:28:32.140488  \n",
      "13            146.0  2024-06-16 15:28:32.140488  \n",
      "14            107.0  2024-08-01 15:28:32.140488  \n",
      "15             96.0  2023-11-09 15:28:32.140488  \n",
      "16             98.0  2024-03-12 15:28:32.140488  \n",
      "17            135.0  2024-03-09 15:28:32.140488  \n",
      "18            171.0  2023-12-06 15:28:32.140488  \n",
      "19            262.0  2023-11-15 15:28:32.140488  \n",
      "20            146.0  2023-12-19 15:28:32.140488  \n",
      "21            157.0  2024-03-15 15:28:32.140488  \n",
      "22            190.0  2023-09-14 15:28:32.140488  \n",
      "23            286.0  2024-07-19 15:28:32.140488  \n",
      "24            194.0  2023-10-14 15:28:32.140488  \n",
      "25            225.0  2024-06-06 15:28:32.140488  \n",
      "26            183.0  2023-11-07 15:28:32.140488  \n",
      "27            109.0  2024-08-03 15:28:32.140488  \n",
      "28            182.0  2023-12-20 15:28:32.140488  \n",
      "29             90.0  2023-09-15 15:28:32.140488  \n",
      "30            192.0  2023-12-30 15:28:32.140488  \n",
      "31            175.0  2024-08-19 15:28:32.140488  \n",
      "32            281.0  2023-11-15 15:28:32.140488  \n",
      "33            238.0  2024-03-22 15:28:32.140488  \n",
      "34            177.0  2024-07-26 15:28:32.140488  \n",
      "35             76.0  2024-07-25 15:28:32.140488  \n",
      "36            230.0  2023-09-05 15:28:32.140488  \n",
      "37            139.0  2023-10-12 15:28:32.140488  \n",
      "38            217.0  2023-11-16 15:28:32.140488  \n",
      "39            277.0  2024-03-09 15:28:32.140488  \n",
      "40             53.0  2024-06-17 15:28:32.140488  \n",
      "41            223.0  2023-12-01 15:28:32.140488  \n",
      "42            243.0  2024-03-24 15:28:32.140488  \n",
      "43            247.0  2024-02-18 15:28:32.140488  \n",
      "44            128.0  2023-08-25 15:28:32.140488  \n",
      "45             83.0  2024-01-07 15:28:32.140488  \n",
      "46            264.0  2024-05-08 15:28:32.140488  \n",
      "47            298.0  2024-03-11 15:28:32.140488  \n",
      "48             78.0  2024-02-18 15:28:32.140488  \n",
      "49            125.0  2024-03-01 15:28:32.140488  >\n"
     ]
    }
   ],
   "source": [
    "# Print the column names and their data types\n",
    "print(\"\\nColumn names and their data types:\\n\")\n",
    "\n",
    "# insert code here \n",
    "print(customer_data.head) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647fd7c-e95c-4647-9770-d08ae34f3f35",
   "metadata": {},
   "source": [
    "Next, you'll use the `df.describe()` function, which generates descriptive statistics for the numerical columns in the DataFrame.\n",
    "\n",
    "In the cell below, use `df.describe()` to display summary statistics for the numerical columns in the `customer_data` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59033260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics for numerical columns:\n",
      "\n",
      "       customer_id        age  purchase_count  total_spend  avg_order_value\n",
      "count     50.00000  50.000000        50.00000    50.000000        50.000000\n",
      "mean    1025.50000  43.440000         8.60000  1491.880000       179.920000\n",
      "std       14.57738  14.833993         4.28095   968.697666        70.820221\n",
      "min     1001.00000  19.000000         1.00000   199.000000        53.000000\n",
      "25%     1013.25000  30.000000         5.00000   819.000000       125.750000\n",
      "50%     1025.50000  44.500000         8.00000  1350.000000       180.000000\n",
      "75%     1037.75000  54.000000        12.00000  1916.000000       237.500000\n",
      "max     1050.00000  69.000000        15.00000  4440.000000       299.000000\n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive statistics for numerical columns:\\n\")\n",
    "\n",
    "# insert code here \n",
    "print(customer_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ed4d5-9198-4bfd-a26f-e239c0246d0b",
   "metadata": {},
   "source": [
    "Finally, in the code cell below, you'll use the `.mean()` and `.median()` functions on the `'age'` column of your `customer_data` to calculate the average and median age of all your customers. \n",
    "\n",
    "The square brackets [] are used for column selection in Pandas. Within the brackets, you specify the name of the column you want to extract, which in this case is 'age'\n",
    "\n",
    "Run the cell to see the average and median age of your customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c7951d-733d-4661-a012-4c020ba3d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Age: 0     54\n",
      "1     66\n",
      "2     56\n",
      "3     44\n",
      "4     25\n",
      "5     69\n",
      "6     63\n",
      "7     24\n",
      "8     59\n",
      "9     31\n",
      "10    24\n",
      "11    54\n",
      "12    29\n",
      "13    45\n",
      "14    53\n",
      "15    64\n",
      "16    63\n",
      "17    33\n",
      "18    43\n",
      "19    19\n",
      "20    38\n",
      "21    69\n",
      "22    48\n",
      "23    43\n",
      "24    51\n",
      "25    55\n",
      "26    43\n",
      "27    38\n",
      "28    51\n",
      "29    30\n",
      "30    53\n",
      "31    57\n",
      "32    20\n",
      "33    28\n",
      "34    64\n",
      "35    47\n",
      "36    45\n",
      "37    41\n",
      "38    51\n",
      "39    23\n",
      "40    29\n",
      "41    20\n",
      "42    31\n",
      "43    52\n",
      "44    63\n",
      "45    30\n",
      "46    38\n",
      "47    49\n",
      "48    23\n",
      "49    24\n",
      "Name: age, dtype: int64\n",
      "\n",
      "Median Age: 0     54\n",
      "1     66\n",
      "2     56\n",
      "3     44\n",
      "4     25\n",
      "5     69\n",
      "6     63\n",
      "7     24\n",
      "8     59\n",
      "9     31\n",
      "10    24\n",
      "11    54\n",
      "12    29\n",
      "13    45\n",
      "14    53\n",
      "15    64\n",
      "16    63\n",
      "17    33\n",
      "18    43\n",
      "19    19\n",
      "20    38\n",
      "21    69\n",
      "22    48\n",
      "23    43\n",
      "24    51\n",
      "25    55\n",
      "26    43\n",
      "27    38\n",
      "28    51\n",
      "29    30\n",
      "30    53\n",
      "31    57\n",
      "32    20\n",
      "33    28\n",
      "34    64\n",
      "35    47\n",
      "36    45\n",
      "37    41\n",
      "38    51\n",
      "39    23\n",
      "40    29\n",
      "41    20\n",
      "42    31\n",
      "43    52\n",
      "44    63\n",
      "45    30\n",
      "46    38\n",
      "47    49\n",
      "48    23\n",
      "49    24\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the 'age' column\n",
    "mean_age = customer_data['age'] # insert code here \n",
    "\n",
    "# Print the mean age\n",
    "print(\"\\nMean Age:\", mean_age)\n",
    "\n",
    "# Calculate the median of the 'age' column\n",
    "median_age = customer_data['age'] # insert code here \n",
    "\n",
    "# Print the median age\n",
    "print(\"\\nMedian Age:\", median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b7f55",
   "metadata": {},
   "source": [
    "## Activity Recap: Charting the Customer Journey with Pandas\n",
    "\n",
    "Congratulations! In this activity, you learned how to load a CSV file into a Pandas DataFrame and use various functions to inspect its structure and contents:\n",
    "\n",
    "* `pd.read_csv()` is used to load CSV data into a DataFrame.\n",
    "* `df.head()` shows the first few rows.\n",
    "* `df.info()` provides a summary of the DataFrame's structure.\n",
    "* `df.describe()` generates descriptive statistics for numerical columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
